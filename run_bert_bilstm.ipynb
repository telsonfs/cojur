{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\";\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"; "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ktrain\n",
    "from ktrain import text as txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "detected encoding: utf-8 (if wrong, set manually)\n",
      "Number of sentences:  6719\n",
      "Number of words in the dataset:  11441\n",
      "Tags: ['B-EC', 'I-LDEL', 'I-MP', 'O', 'I-DLEI', 'B-MP', 'I-EC', 'B-DEC', 'B-LCOMP', 'I-LCOMP', 'I-LEI', 'B-LDEL', 'I-DEC', 'B-LEI', 'I-DLEG', 'B-DLEG', 'B-DLEI']\n",
      "Number of Labels:  17\n",
      "Longest sentence: 1557 words\n"
     ]
    }
   ],
   "source": [
    "TDATA = 'dataset/train.txt'\n",
    "VDATA = 'dataset/test.txt'\n",
    "(trn, val, preproc) = txt.entities_from_conll2003(TDATA, val_filepath=VDATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding schemes employed (combined with concatenation):\n",
      "\tword embeddings initialized with fasttext word vectors (cc.nl.300.vec.gz)\n",
      "\tBERT embeddings with wietsedv/bert-base-dutch-cased\n",
      "\n",
      "pretrained word embeddings will be loaded from:\n",
      "\thttps://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.nl.300.vec.gz\n",
      "loading pretrained word vectors...this may take a few moments...\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "WV_URL='https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.nl.300.vec.gz'\n",
    "model = txt.sequence_tagger('bilstm-bert', preproc, \n",
    "                            bert_model='wietsedv/bert-base-dutch-cased', wv_path_or_url=WV_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner = ktrain.get_learner(model, train_data=trn, val_data=val, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preparing training data ...done.\n",
      "preparing validation data ...done.\n",
      "Epoch 1/50\n",
      "62/62 [==============================] - 2630s 42s/step - loss: 0.1089 - val_loss: 0.0918\n",
      "Epoch 2/50\n",
      "62/62 [==============================] - 2589s 42s/step - loss: 0.0415 - val_loss: 0.0520\n",
      "Epoch 3/50\n",
      "62/62 [==============================] - 2605s 42s/step - loss: 0.0263 - val_loss: 0.0422\n",
      "Epoch 4/50\n",
      "28/62 [============>.................] - ETA: 20:36 - loss: 0.0198"
     ]
    }
   ],
   "source": [
    "learner.fit(0.01, 1, cycle_len=50, checkpoint_folder='/tmp/saved_weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "No training history - did you train the model yet?",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-cf313d8ba728>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlearner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/ktrain/core.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, plot_type, return_fig)\u001b[0m\n\u001b[1;32m    631\u001b[0m         \"\"\"\n\u001b[1;32m    632\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 633\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'No training history - did you train the model yet?'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    634\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m         \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: No training history - did you train the model yet?"
     ]
    }
   ],
   "source": [
    "learner.plot('lr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   F1:  90.91\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         DEC       0.83      1.00      0.91         5\n",
      "\n",
      "   micro avg       0.83      1.00      0.91         5\n",
      "   macro avg       0.83      1.00      0.91         5\n",
      "weighted avg       0.83      1.00      0.91         5\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9090909090909091"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner.validate(class_names=preproc.get_classes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-2-3-gpu.2-3.m59",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-2-3-gpu.2-3:m59"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
